{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4986024",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ffee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.datasets import make_classification\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pycld2 as cld2\n",
    "from langdetect import detect\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score, classification_report \n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import RocCurveDisplay, plot_roc_curve\n",
    "from transformers import BertConfig, BertTokenizer, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12306168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/WELFake_Dataset.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db641bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92022f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['title'].isna() & df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['title'].isna() | df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b75825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b97007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02fcba2",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "## With NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2fbb7c",
   "metadata": {},
   "source": [
    "### Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043308c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)           # sequences of white spaces\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)  # Removing all the non ASCII characters\n",
    "    text = re.sub(r'\\s+',' ', text)            # Replacing multiple Spaces with Single Space\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)        # Replacing Two or more dots with one\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)  # Removing all the non ASCII characters\n",
    "    text = re.sub(r'\\W+',' ', text)            # Replace everything non-alpahnumeric with a space\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad59b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].map(clean)\n",
    "df['title_clean'] = df['title'].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a77d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"empty_cell_text\"] = df['text_clean'].str.contains(r'^\\s*$', na=False)\n",
    "df[\"empty_cell_title\"] = df['title_clean'].str.contains(r'^\\s*$', na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ccbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e1a96",
   "metadata": {},
   "source": [
    "### Removing empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7293250",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop(df.loc[df[\"empty_cell_text\" or \"empty_cell_title\"]].index, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop(columns=[\"empty_cell_text\", \"empty_cell_title\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"data/df_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c04487",
   "metadata": {},
   "source": [
    "### Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425677e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(text):\n",
    "    _, _, _, detected_language = cld2.detect(text, returnVectors=True)\n",
    "    return str(detected_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45128b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lang'] = df['text_clean'].map(detect_lang)\n",
    "df['title_lang'] = df['title_clean'].map(detect_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4579d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['text_lang'].astype(str)\n",
    "df['title_lang'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fc81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lang'] = ~df[\"text_lang\"].str.contains('ENGLISH|Unknown', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_lang'] = ~df[\"title_lang\"].str.contains('ENGLISH|Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d158929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df[\"text_lang\" or \"title_lang\"]].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49241ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0343ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326c9a19",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be23080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "df['token_title'] = df.apply(lambda row: nltk.word_tokenize(row['title_clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_text'] = df.apply(lambda row: nltk.word_tokenize(row['text_clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"text_lang\", \"title_lang\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/df_token.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6de81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"df_token.csv\")\n",
    "#df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b51ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.token_title[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e6072f",
   "metadata": {},
   "source": [
    "### POS tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80892b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0e79a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['tag_title'] = df.apply(lambda row: nltk.pos_tag(row['token_title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5e091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag_text'] = df.apply(lambda row: nltk.pos_tag(row['token_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec4b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tag_title[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad49f9",
   "metadata": {},
   "source": [
    "### Lemmatizing tagged words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c8be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(words):\n",
    "    lemmatized_words = [lem.lemmatize(word) for word in words]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e523fc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lem_title'] = df.apply(lambda row: lemmatize(row['token_title']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64602d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lem_text'] = df.apply(lambda row: lemmatize(row['token_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a29d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db4cfaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/df_lemmatized.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183891b5",
   "metadata": {},
   "source": [
    "for word, tag in enumerate(df['tag_title']):\n",
    "         wntag = tag[0][0][0].lower()\n",
    "         wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "         lemma = lem.lemmatize(word, wntag) if wntag else word\n",
    "         print (lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1e257",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6934b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = list(stopwords.words('english')) \n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d96650",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(stop_words)):\n",
    "    stop_words[i] = re.sub(r\"\\s*'\\s*\\w*\",\"\",stop_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952b49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stop_title\"] = df[\"lem_title\"].apply(lambda x: ' '.join([word for word in x if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"stop_text\"] = df[\"lem_text\"].apply(lambda x: ' '.join([word for word in x if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71e9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1fe215",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/df_stopwords.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c42115",
   "metadata": {},
   "source": [
    "### BOW with countvec [ignore]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e5b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizer(sentences):\n",
    "    vectorizer = CountVectorizer(max_features=100)\n",
    "    X = vectorizer.fit_transform(sentences)\n",
    "    return (vectorizer, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8855d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(vectorizer, X) = create_vectorizer(df.stop_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5161fabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c77fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a617ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseX = X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecc9037",
   "metadata": {},
   "outputs": [],
   "source": [
    "denseX[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe594008",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a647aea",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8f7cf4",
   "metadata": {},
   "source": [
    "### TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc54c398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on titles\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['stop_title'],\n",
    "df['label'],\n",
    "test_size=0.2,\n",
    "random_state=42,\n",
    "stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Size of Training Data ', X_train.shape[0])\n",
    "print ('Size of Test Data ', X_test.shape[0])\n",
    "print ('Distribution of classes in Training Data :')\n",
    "print ('Fake item ', str(sum(Y_train == 1)/ len(Y_train) * 100.0))\n",
    "print ('Real item ', str(sum(Y_train == 0)/ len(Y_train) * 100.0))\n",
    "print ('Distribution of classes in Testing Data :')\n",
    "print ('Fake item ', str(sum(Y_test == 1)/ len(Y_test) * 100.0))\n",
    "print ('Real item ', str(sum(Y_test == 0)/ len(Y_test) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f7f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features = 20000, ngram_range=(1,2))\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ece6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = LinearSVC(random_state=42, tol=1e-5)\n",
    "SVC.fit(X_train_tf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea48532",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = SVC.predict(X_test_tf)\n",
    "print ('Accuracy Score - ', accuracy_score(Y_test, Y_pred))\n",
    "print ('ROC-AUC Score - ', roc_auc_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31e7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on text\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(df['stop_text'],\n",
    "df['label'],\n",
    "test_size=0.2,\n",
    "random_state=42,\n",
    "stratify=df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc33263",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Size of Training Data ', X_train.shape[0])\n",
    "print ('Size of Test Data ', X_test.shape[0])\n",
    "print ('Distribution of classes in Training Data :')\n",
    "print ('Fake item ', str(sum(Y_train == 1)/ len(Y_train) * 100.0))\n",
    "print ('Real item ', str(sum(Y_train == 0)/ len(Y_train) * 100.0))\n",
    "print ('Distribution of classes in Testing Data :')\n",
    "print ('Fake item ', str(sum(Y_test == 1)/ len(Y_test) * 100.0))\n",
    "print ('Real item ', str(sum(Y_test == 0)/ len(Y_test) * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f46676",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer = 'word', max_features = 20000, ngram_range=(1,2))\n",
    "X_train_tf = tfidf.fit_transform(X_train)\n",
    "X_test_tf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b28f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = LinearSVC(random_state=42, tol=1e-5)\n",
    "SVC.fit(X_train_tf, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d82e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = SVC.predict(X_test_tf)\n",
    "print ('Accuracy Score - ', accuracy_score(Y_test, Y_pred))\n",
    "print ('ROC-AUC Score - ', roc_auc_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97081fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7955fe9",
   "metadata": {},
   "source": [
    "## Pretrained models and Transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fbf0bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = BertConfig.from_pretrained('bert-base-uncased',finetuning_task='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085b6678",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7287a6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab9bc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
