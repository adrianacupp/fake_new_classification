{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4986024",
   "metadata": {},
   "source": [
    "# Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "032725b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/adrianacuppuleri/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.datasets import make_classification\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "import pycld2 as cld2\n",
    "from langdetect import detect\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12306168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"WELFake_Dataset.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db641bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92022f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b15658b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['title'].isna() & df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc1eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['title'].isna() | df['text'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b75825",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b97007",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02fcba2",
   "metadata": {},
   "source": [
    "# Text preprocessing\n",
    "## With NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2fbb7c",
   "metadata": {},
   "source": [
    "### Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043308c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\s+', ' ', text)           # sequences of white spaces\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)  # Removing all the non ASCII characters\n",
    "    text = re.sub(r'\\s+',' ', text)            # Replacing multiple Spaces with Single Space\n",
    "    text = re.sub(r'\\.{2,}', ' ', text)        # Replacing Two or more dots with one\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)  # Removing all the non ASCII characters\n",
    "    text = re.sub(r'\\W+',' ', text)            # Replace everything non-alpahnumeric with a space\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad59b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_clean'] = df['text'].map(clean)\n",
    "df['title_clean'] = df['title'].map(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a77d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"empty_cell_text\"] = df['text_clean'].str.contains(r'^\\s*$', na=False)\n",
    "df[\"empty_cell_title\"] = df['title_clean'].str.contains(r'^\\s*$', na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355ccbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11e1a96",
   "metadata": {},
   "source": [
    "### Removing empty cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7293250",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.drop(df.loc[df[\"empty_cell_text\" or \"empty_cell_title\"]].index, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5919917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)\n",
    "df.drop(columns=[\"empty_cell_text\", \"empty_cell_title\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46e769",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b025f554",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"df_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c04487",
   "metadata": {},
   "source": [
    "### Language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425677e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_lang(text):\n",
    "    _, _, _, detected_language = cld2.detect(text, returnVectors=True)\n",
    "    return str(detected_language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45128b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lang'] = df['text_clean'].map(detect_lang)\n",
    "df['title_lang'] = df['title_clean'].map(detect_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b4579d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['text_lang'].astype(str)\n",
    "df['title_lang'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3fc81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_lang'] = ~df[\"text_lang\"].str.contains('ENGLISH|Unknown', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_lang'] = ~df[\"title_lang\"].str.contains('ENGLISH|Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e15e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d158929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df[\"text_lang\" or \"title_lang\"]].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49241ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0343ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326c9a19",
   "metadata": {},
   "source": [
    "### Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be23080",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.data.load(\"tokenizers/punkt/english.pickle\")\n",
    "df['token_title'] = df.apply(lambda row: nltk.word_tokenize(row['title_clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f2eafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['token_text'] = df.apply(lambda row: nltk.word_tokenize(row['text_clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75c6ba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27b8a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=[\"text_lang\", \"title_lang\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd48a49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"df_token.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc6de81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_token.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ad49f9",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3d0745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag, word_tokenize,pos_tag_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cf0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d9f32291",
   "metadata": {},
   "source": [
    "def lemmatize(words):\n",
    "    lemmatized_words = [lem.lemmatize(word) for word in df['token_title']]\n",
    "    return lemmatized_words"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7fefdc51",
   "metadata": {},
   "source": [
    "#the function lem on the col token_title return tokens but not lemma, therefore the above cell won't work as well\n",
    "[lem.lemmatize(word) for word in df['token_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007651f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = 'These sentences involves some horsing around'\n",
    ">>> for word, tag in pos_tag(word_tokenize(sent)):\n",
    "...     wntag = tag[0].lower()\n",
    "...     wntag = wntag if wntag in ['a', 'r', 'n', 'v'] else None\n",
    "...     lemma = lem.lemmatize(word, wntag) if wntag else word\n",
    "...     print (lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a6beb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df['title_clean'].tolist()\n",
    "title=[]\n",
    "for i in text:\n",
    "   title.append(str(i))\n",
    "\n",
    "tagged_texts = pos_tag_sents(map(word_tokenize, title))\n",
    "df[\"POS_title\"]=tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386d0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=df['text_clean'].tolist()\n",
    "title=[]\n",
    "for i in text:\n",
    "   title.append(str(i))\n",
    "\n",
    "tagged_texts = pos_tag_sents(map(word_tokenize, title))\n",
    "df[\"POS_text\"]=tagged_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab475b46",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae1e257",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c42115",
   "metadata": {},
   "source": [
    "### Frequency"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
